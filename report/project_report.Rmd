---
title: 'BIOS 735 Final Project: Car Accident Severity'
author: "Marissa Ashner, Yen Chang, Marco Chen, Weifang Liu, Yi Tang, Joyce Yan"
date: "4/27/2020"
output:
  html_document:
    df_print: paged
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction 

Sitting in traffic is not ideal for anyone, and it is especially frustrating when the traffic is caused by an accident. It is an unexpected delay, and many times it is completely uncertain how long the delay will last. Traffic accident data can be an invaluble resource, as it can provide information that can potentially aid in predicting conditions where accidents are prone to happen so steps can be taken to prevent the accident. Further, this data could be useful in predicting how severely an accident will delay the following drivers after the accident happens so steps can be taken to reduce this delay as needed. 

Several computer scientists from the Ohio State University present exactly this: a dataset of traffic accidents from the contiguous United States, covering 2.95 million accidents with data collected between February 2016 and December 2019. As of March 2019, of the 49 states included, North Carolina had the fourth highest number of accidents in the dataset at 109,000 [1]. Because of the wide range of attributes collected with each accident in the dataset, this has the potential to provide the information needed to start making decisions about how to prevent accidents and the delays associated.

# Project Aim 

The aim of this project is to use Car Accident Data from North Carolina in 2016-2018 to determine which factors have the most influence on the severity of car accidents in the state. We take two different approaches to construct models to predict the severity of car accidents, one through proportional oddes model and one through machine learning. We then use the 2019 data to evaluate and compare the performance of our prediction models.

# R-Package

Our R package `group3project` contains functions to fit a proportional odds model, random forest....

```{r}
## load package here 
```

# Data

The final dataset used contains 119,279 traffic accidents from North Carolina between the years 2016 and 2019. The original dataset had 49 total attributes, including attributes related to traffic, location, weather, points of interest, and period of day. For our purposes, we removed all location attributes.(?? not done yet) We also chose to remove Wind Chill and Precipitation since they had around 60% missingess. Additionally, most of the points of interest variables had very low variability, so we chose only to keep Crossing and Traffic Signal (TRUE/FALSE variables) (not correct right now in filtered dataset).

```{r}
data_filtered <- read.csv("../data/NC_Accidents_filtered.csv")
```

Variables:  
      (YC: (i) would this be easier to read if we group by their role in the analysis(outcome/predictor candidates/dropped)?
           (ii)Do we start with the same set subset of variables for both proportional odds model and RF?)
           
The Final Selection of Variables is as follows: 

**Outcome: **
1. Severity:  severity of the accident in terms of the impact on traffic, which is an integer from 1 to 4 with increasing impact. This is an ordinal variable and the outcome of interest.  

(YC: the dataset and paper is rather vague on how severity is defined or derived. Length of delay is the only criterion they explicitly mentioned? I would guess that scope, for example how many lanes affected, is probably taken into account?)

**Predictors: **  
1. Source (API that reported accident) -- remove  
2. Start Time -- start time of the accident. keep the hour and minute of the day? aggregate?, keep month?  
3. End Time   
4. Start Lat -- remove 
5. Start Lng -- remove  
6. Description (in Natural Language) -- remove for now?  
8. Street (Name) -- remove  
9. Side (of Street -- R/L)  
10. City -- remove for now? or aggregate rural/urban? (YC: then we need some way to distinguish between rural/urban)  
11. County -- remove for now? or aggregate rural/urban?  
12. State -- remove  
13. Zipcode -- remove   
14. Country -- remove  
15. Timezone -- remove   
16. Airport Code -- remove  
17. Weather Timestamp -- remove  
18. Temperature   
19. Humidity (%)  
20. Pressure (Air, in inches)  
21. Visibility (in miles)   
22. Wind Direction --- aggregate CALM vs NOT CALM?  
23. Wind Speed (mph)   
24. Weather Condition -- aggregate? (53 factors)  
25. Crossing (presence of crossing nearby)  
26. Traffic_Signal   
27. Sunrise_Sunset   
28. Civil_Twilight -- remove  
29. Nautical_Twilight -- remove  
30. Astronomical_Twilight -- remove  

# Methods 
First, we apply a proportional odds model with the severity of an accident as the outcome, and start time ,<---insert list of candidate variables--->, as predictors. Based on paramter estimates of this model <---potentially with penalization--->, we identify variables that are most associated with severirty. In parallel, <--starting with the same set of variables?-->we use random forest to find the predictors that best yields the best classification.  



## Proportional Odds Model  
For a single severity outcome $Y_i$ with covariates $X_i$, the proportional odds model suggests that 
$$ logit(P(Y_i\leq k))=log(\frac{P(Y_i\leq k)}{1-P(Y_i\leq k)}) = \alpha_k + X_i^T\beta$$
, or equivalently

$$ P(Y_i\leq k) = \frac{1}{1 + exp(-\alpha_k - X_i^T\beta)}$$
for k=1, 2, and 3. The log likelihood function for n accidents is therefore given by (YC: here I use a slightly different notation than the one used by Marco (note the sign of alpha))
$$\sum_{i=1}^n\sum_{k=1}^4I(Y_i=k)log(P(Y_i=k))\\
=\sum_{i=1}^n \{I(Y_i=1)log(P(Yi\le1))+ I(Y_i=2)[log(P(Yi\le2)-P(Y_i\le1)] + I(Y_i=3)[log(P(Yi\le3)-P(Y_i\le2)] + I(Y_i=4)[log(1-P(Y_i\le3)]\}\\
=\sum_{i=1}^n\{I(Y_i=1)log(\frac{1}{1+exp(-\alpha_1 - X_i^T\beta)})+ I(Y_i=2)log(\frac{1}{1+exp(-\alpha_2 - X_i^T\beta)}-\frac{1}{1+exp(-\alpha_1 - X_i^T\beta)})+ \\I(Y_i=3)log(\frac{1}{1+exp(-\alpha_3 - X_i^T\beta)}-\frac{1}{1+exp(-\alpha_2 - X_i^T\beta)})+ I(Y_i=2)log(\frac{1}{1+exp(-\alpha_2 - X_i^T\beta)}-\frac{1}{1+exp(-\alpha_1 - X_i^T\beta)})\}$$
(YC: Do we want to access the proportional odds assumption?)

## Random Forest

# Results 

## Proportional Odds Model 

## Random Forest

## Method Comparison 

# Discussion 

# Data References 

Source of data: https://www.kaggle.com/sobhanmoosavi/us-accidents

[1] Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv
      Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.
  
[2] Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu
      Teodorescu, and Rajiv Ramnath. "Accident Risk Prediction based on Heterogeneous
      Sparse Data: New Dataset and Insights." In proceedings of the 27th ACM SIGSPATIAL
      International Conference on Advances in Geographic Information Systems, ACM, 2019.

