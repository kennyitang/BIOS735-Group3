---
title: 'BIOS 735 Final Project: Car Accident Severity'
author: "Marissa Ashner, Yen Chang, Marco Chen, Weifang Liu, Yi Tang, Joyce Yan"
date: "4/27/2020"
output:
  html_document:
    df_print: paged
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction 

Sitting in traffic is not ideal for anyone, and it is especially frustrating when the traffic is caused by an accident. It is an unexpected delay, and many times it is completely uncertain how long the delay will last. Traffic accident data can be an invaluble resource, as it can provide information that can potentially aid in predicting conditions where accidents are prone to happen so steps can be taken to prevent the accident. Further, this data could be useful in predicting how severely an accident will delay the following drivers after the accident happens so steps can be taken to reduce this delay as needed. 

Several computer scientists from the Ohio State University present exactly this: a dataset of traffic accidents from the contiguous United States, covering 2.25 accidents between February 2016 and December 2019. As of March 2019, of the 49 states included, North Carolina had the fourth highest number of accidents in the dataset at 109,000 [1]. Because of the wide range of attributes collected with each accident in the dataset, this has the potential to provide the information needed to start making decisions about how to prevent accidents and the delays associated.

# Project Aim 

The aim of this project is to use Car Accident Data from North Carolina in 2016-2018 to determine which factors have the most influence on the severity of car accidents in the state. We take two different approaches to construct models to predict the severity of car accidents, one through proportional oddes model and one through machine learning. We then use the 2019 data to evaluate and compare the performance of our prediction models.

# R-Package

Our R package `name` contains functions to fit a proportional odds model, random forest....

```{r}
## load package here 
```

# Data

The dataset used contains 142,460 traffic accidents from North Carolina between the years 2016 and 2019. The original dataset had 49 total attributes, including attributes related to traffic, location, weather, points of interest, and period of day. For our purposes, we removed all location attributes. We also chose to remove Wind Chill and Precipitation since they had around 60% missingess.

```{r}
data <- read.csv("NC_Accidents.csv")
data_filtered <- data %>% select(ID, Severity, Start_Time, End_Time, Distance.mi., 
                                 Side, Temperature.F., Humidity..., Pressure.in.,
                                 Visibility.mi., Wind_Direction, Wind_Speed.mph., 
                                 Weather_Condition, Amenity, Bump, Crossing, Give_Way, 
                                 Junction, 
                                 No_Exit, Railway, Roundabout, Station, Stop, 
                                 Traffic_Calming, Traffic_Signal, Turning_Loop,
                                 Sunrise_Sunset) %>% 
  mutate(Month = (Start_Time %>% as.POSIXlt())$mon + 1, Hour =  (Start_Time %>% as.POSIXlt())$hour) %>% 
  select(-Start_Time)
```

Variables:  
      (YC: (i) would this be easier to read if we group by their role in the analysis(outcome/predictor candidates/dropped)?
           (ii)Do we start with the same set subset of variables for both proportional odds model and RF?)
      
1. ID -- no duplicated IDs, all unique 
2. Source (API that reported accident) -- remove
3. TMC -- Traffic Message Channel (TMC) code, remove
4. Severity -- severity of the accident in terms of the impact on traffic, which is an integer from 1 to 4 with increasing impact. This is an ordinal variable and the outcome of interest.  

(YC: the dataset and paper is rather vague on how severity is defined or derived. Length of delay is the only criterion they explicitly mentioned? I would guess that scope, for example how many lanes affected, is probably taken into account?)

5. Start Time -- start time of the accident. keep the hour and minute of the day? aggregate?, keep month?
6. End Time 
7. Start Lat -- remove 
8. Start Lng -- remove
9. End Lat -- remove
10. End Lng -- remove
11. Distance (Length of road extent affected by accident) -- only 13% is nonzero? (YC: probably because the unit is mile)
12. Description (in Natural Language) -- remove for now?
13. Number (Street) -- remove
14. Street (Name) -- remove
15. Side (of Street -- R/L)
16. City -- remove for now? or aggregate rural/urban? (YC: then we need some way to distinguish between rural/urban)
17. County -- remove for now? or aggregate rural/urban?
18. State -- remove
19. Zipcode -- remove 
20. Country -- remove
21. Timezone -- remove 
22. Airport Code -- remove
23. Weather Timestamp -- remove
24. Temperature 
25. Wind Chill  -- heavy missingness, remove
26. Humidity (%)
27. Pressure (Air, in inches)
28. Visibility (in miles) 
29. Wind Direction --- aggregate CALM vs NOT CALM?
30. Wind Speed (mph) 
31. Precipitation (in inches) -- remove missingness
32. Weather Condition -- aggregate? (53 factors)
33. Amenity 
34. Bump (presence of speed bump in nearby location)
35. Crossing (presence of crossing nearby)
36. Give_Way (presence of give_way sign nearby)
37. Junction (presence of junction nearby)
38. No_Exit (presence of no_exit sign nearby)
39. Railway (presence of railway nearby)
40. Roundabout 
41. Station 
42. Stop (sign)
43. Traffic_Calming 
44. Traffic_Signal 
45. Turning_Loop
46. Sunrise_Sunset 
47. Civil_Twilight -- remove
48. Nautical_Twilight -- remove
49. Astronomical_Twilight -- remove



# Methods 
First, we apply a proportional odds model with the severity of an accident as the outcome, and start time ,<---insert list of candidate variables--->, as predictors. Based on paramter estimates of this model <---potentially with penalization--->, we identify variables that are most associated with severirty. In parallel, <--starting with the same set of variables?-->we use random forest to find the predictors that best yields the best classification.  



## Proportional Odds Model  
For a single severity outcome $Y_i$ with covariates $X_i$, the proportional odds model suggests that 
$$ logit(P(Y_i\leq k))=log(\frac{P(Y_i\leq k)}{1-P(Y_i\leq k)}) = \alpha_k + X_i^T\beta$$
, or equivalently

$$ P(Y_i\leq k) = \frac{1}{1 + exp(-\alpha_k - X_i^T\beta)}$$
for k=1, 2, and 3. The log likelihood function for n accidents is therefore given by (YC: here I use a slightly different notation than the one used by Marco (note the sign of alpha))
$$\sum_{i=1}^n\sum_{k=1}^4I(Y_i=k)log(P(Y_i=k))\\
=\sum_{i=1}^n \{I(Y_i=1)log(P(Yi\le1))+ I(Y_i=2)[log(P(Yi\le2)-P(Y_i\le1)] + I(Y_i=3)[log(P(Yi\le3)-P(Y_i\le2)] + I(Y_i=4)[log(1-P(Y_i\le3)]\}\\
=\sum_{i=1}^n\{I(Y_i=1)log(\frac{1}{1+exp(-\alpha_1 - X_i^T\beta)})+ I(Y_i=2)log(\frac{1}{1+exp(-\alpha_2 - X_i^T\beta)}-\frac{1}{1+exp(-\alpha_1 - X_i^T\beta)})+ \\I(Y_i=3)log(\frac{1}{1+exp(-\alpha_3 - X_i^T\beta)}-\frac{1}{1+exp(-\alpha_2 - X_i^T\beta)})+ I(Y_i=2)log(\frac{1}{1+exp(-\alpha_2 - X_i^T\beta)}-\frac{1}{1+exp(-\alpha_1 - X_i^T\beta)})\}$$
(YC: Do we want to access the proportional odds assumption?)

## Random Forest

# Results 

## Proportional Odds Model 

## Random Forest

## Method Comparison 

# Discussion 

# Data References 

Source of data: https://www.kaggle.com/sobhanmoosavi/us-accidents

[1] Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv
      Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.
  
[2] Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu
      Teodorescu, and Rajiv Ramnath. "Accident Risk Prediction based on Heterogeneous
      Sparse Data: New Dataset and Insights." In proceedings of the 27th ACM SIGSPATIAL
      International Conference on Advances in Geographic Information Systems, ACM, 2019.

