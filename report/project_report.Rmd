---
title: 'BIOS 735 Final Project: Car Accident Severity'
author: "Marissa Ashner, Yen Chang, Marco Chen, Yi Tang Chen, Weifang Liu, Joyce Yan"
date: "4/23/2020"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
```

# Introduction 

Sitting in traffic is not ideal for anyone, and it is especially frustrating when the traffic is caused by an accident. It is an unexpected delay, and many times it is completely uncertain how long the delay will last. Moreso, traffic accidents pose a big problem for public safety. Traffic accident data can be an invaluble resource, as it can provide information that can potentially aid in predicting conditions where accidents are prone to happen so steps can be taken to prevent the accident. Further, this data could be useful in predicting how severely an accident will delay the drivers following the accident so steps can be taken to reduce this delay as needed. 

Several computer scientists from the Ohio State University present exactly this: a dataset of traffic accidents from the contiguous United States, covering 2.95 million accidents with data collected between February 2016 and December 2019. As of March 2019, of the 49 states included, North Carolina had the fourth highest number of accidents in the dataset at 109,000 [1]. Because of the wide range of attributes collected with each accident in the dataset, this has the potential to provide the information needed to start making decisions about how to prevent accidents and the delays associated.

# Project Aim 

The aim of this project is to use Car Accident Data from North Carolina in 2016-2018 to determine which factors have the most influence on the severity of car accidents in the state. We take two different approaches to construct models to predict the severity of car accidents, one through proportional odds model and one through machine learning. We then use the 2019 data to evaluate and compare the performance of our prediction models.

# R-Package

Our R package `group3project` contains the functions needed to fit a proportional odds model and random forest as well as the datasets we used to do so for this report: 

*Note: edit this as needed as we fill in the R package

* Functions for Proportional Odds Model
    + loglik.pom: computes log likelihood of a proportional odds model
    + gradient.pom:      <--which one to use?
    + gradient.pom2:
    

* Functions for Random Forest
    + calc_acc: calculates accuracy of classification

* Datasets 
    + Testing Data 
    + Training Data
    + Full NC Data


```{r}
## load package here
library(png)
library(grid)
```

# Data
The original dataset had 49 total attributes, including attributes related to traffic, location, weather, points of interest, and period of day.  Pre-processing the data set was necessary to allow us to focus on the variables and observations of real relevance to our aim. Although we started out with 48 dependent variables and one outcome variable, there were several reasons for removing most of the attributes, including:  

1. The attribute had at least 60% missingness.
    + Wind Chill and Precipitation
2. The attribute had very low or no variability across the observations.  
    + after aggregating the County variable into urban and rural factor levels, it was apparent that about 95% of the accident data was derived from urban areas, therefore variables such as County, Zip-Code, and City were not of use 
    + most of the points of interest variables except Crossing and Traffic Signal
3. The attribute was relevant for spatial purposes (i.e. latitude and longitude), which we do not aim to study at this time.

Therefore this information was not useful for prediction.

In terms of traffic incidents, rows missing all weather variables were removed. After pre-processing, the analysis dataset contains 119,279 traffic accidents from North Carolina between the years 2016 and 2019 with 12 attributes and one outcome variable. Additionally, the analysis data were split up into training data (pre-2019) and testing data (2019) as mentioned previously. The final training dataset has 75,887 observations and the testing has 43,392 observations.
  
The variables selected for analysis, and some accompanying exploratory plots are as follows: 

### Outcome:
1. Severity:  severity of the accident in terms of the impact on traffic, which is an integer from 1 to 3 with increasing impact. This is an ordinal variable and the outcome of interest.  

Originally this variable had four categories (1-4), but only 24 observations had severity of 1, so we combined severities 1 and 2 and readjusted the scale.  

It should be noted that the data set sources are rather vague on the definition of this outcome variable. Length of delay caused by the accident is the major determinant, and we assume that scope, such as how many lane closures there were, may also be taken into account when determining the severity. 

### Predictors:

**Location/Time** 

1. Source: categorical, API that reported accident (MapQuest, Bing, MapQuest-Bing)
2. Side: categorical, side of street (Left/Right)  
3. Sunrise_Sunset: categorical (Day/Night)
4. Weekday: TRUE/FALSE, if accident started on a weekday 
5. Interstate: TRUE/FALSE, if accident happened on an interstate
  
**Weather**  

6. Temperature: numeric, degrees Fahrenheit    
7. Humidity: numeric, percentage  
8. Pressure: numeric air pressure, in inches  
9. Visibility: numeric, in miles  
10. Wind Speed: numeric, in mph 

```{r fig.width=8,echo=FALSE}
grid.raster(readPNG("weather_boxplots.png"))
```
  
**Points of Interest**  

11. Crossing: TRUE/FALSE, presence of a crossing nearby for pedestrians, cyclists, etc. 
12. Traffic_Signal: TRUE/FALSE, presence of a traffic signal nearby on an intersection 

```{r fig.width=6,echo=FALSE}
grid.raster(readPNG("crossing.png"))
```

```{r fig.width=6,echo=FALSE}
grid.raster(readPNG("Traffic_Signal.png"))
```

# Methods 
We apply a proportional odds model with severity of an accident as the outcome, and predictors listed in the previous section as covariates. Based on paramter estimates of this model <---potentially with penalization--->, we identify variables that are most associated with severity. In parallel, starting with the same set of variables, we use random forest to find the predictors and build a model that yields the best classification.  


## Proportional Odds Model  
For a single severity outcome $Y_i$ with covariates $X_i$, the usual proportional odds model suggests that 
\[
  {\displaystyle
    \begin{aligned}
      logit(P(Y_i\leq k))=log(\frac{P(Y_i\leq k)}{1-P(Y_i\leq k)}) = \alpha_k - x_i^T\beta\\
      &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad
    \end{aligned}
  }
\], where \(\beta = (\beta_1,...,\beta_p)^T, x_i = (x_{i1},..., x_{ip})^T,\) and \(k= 1, 2\).

<br>

Equivalently, if we define \(\phi(t) = \frac{1}{1+exp(-t)}\), then 
\[  
{\displaystyle
    \begin{aligned}
P(Y_i\leq k) = \frac{1}{1 + exp(x_i^T\beta-\alpha_k)} = \phi(\alpha_k-x_i^T\beta).&\\
                                   & \qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\ 
    \end{aligned}
  }  
\]

If we define $\alpha = (\alpha_1,\alpha_2)^T$, then log likelihood function for n accidents is therefore given by 
\[
  {\displaystyle
    \begin{aligned}
l(\alpha, \beta)&= \sum_{i=1}^n\sum_{k=1}^3I(Y_i=k)log(P(Y_i=k))\\
                &=\sum_{i=1}^n \{I(Y_i=1)log(P(Yi\le1))+ I(Y_i=2)[log(P(Yi\le2)-P(Y_i\le1)] + I(Y_i=3)[log(1-P(Y_i\le2)]\}\\
                &=\sum_{i=1}^n\{I(Y_i=1)log(\phi(\alpha1-x_i^T\beta))+ I(Y_i=2)log(\phi(\alpha2-x_i^T\beta)-\phi(\alpha1-x_i^T\beta))+  I(Y_i=3)log(1-\phi(\alpha2-x_i^T\beta))\}
    \end{aligned}
  }
\].  

The gradient is 
\[
  {\displaystyle
    \begin{aligned}
(\frac{\partial l(\alpha, \beta)}{\partial \beta_1}, ..., \frac{\partial l(\alpha, \beta)}{\partial \beta_p}, \frac{\partial l(\alpha, \beta)}{\partial \alpha_1}, \frac{\partial l(\alpha, \beta)}{\partial \alpha_2})^T&\\
                                   & \qquad\qquad\qquad &\qquad\qquad\qquad &\qquad\qquad\qquad & 
    \end{aligned}
  }
\]

, with the individual elements given below.

<br>

\[
  {\displaystyle
    \begin{aligned}
        \frac{\partial l(\alpha, \beta)}{\partial \beta_j}
          &= \sum_{i=1}^n\left(-I(Y_i=1)\frac{exp(x_i^T\beta-\alpha_1)}{1+exp(x_i^T\beta-\alpha_1)}x_{ij}
            + I(Y_i=2)\frac{\frac{exp(x_i^T\beta-\alpha_1)}{[1+exp(x_i^T\beta-\alpha_1)]^2}-
                \frac{exp(x_i^T\beta-\alpha_2)}{[1+exp(x_i^T\beta-\alpha_2)]^2}}{\phi(\alpha_2-x_i^T\beta)-\phi(\alpha_1-x_i^T\beta)}x_{ij} 
            + I(Y_i=3)\frac{x_{ij}}{1+exp(x_i^T\beta-\alpha_2)}\right)
          \\&=\sum_{i=1}^n\left(-I(Y_i=1)(1-\phi(\alpha_1-x_i^T\beta)) 
            + I(Y_i=2)\frac{\phi(\alpha_1-x_i^T\beta)[1-\phi(\alpha_1-x_i^T\beta)]
              -\phi(\alpha_2-x_i^T\beta)[1-\phi(\alpha_2-x_i^T\beta)]}{\phi(\alpha_2-x_i^T\beta)-\phi(\alpha_1-x_i^T\beta)} 
            +I(Y_i=3)\phi(\alpha_2-x_i^T\beta)\right)x_{ij}\\
        \\
        \frac{\partial l(\alpha, \beta)}{\partial \alpha_1} 
        &= \sum_{i=1}^n \left(I(Y_i=1)\frac{exp(x_i^T\beta-\alpha_1)}{1+exp(x_i^T\beta-\alpha_1)}
          -I(Y_i=2)\frac{\frac{exp(x_i^T\beta-\alpha_1)}{[1+exp(x_i^T\beta-\alpha_1)]^2}}{\phi(\alpha_2-x_i^T\beta)-\phi(\alpha_1-x_i^T\beta)} \right)\\
        &=\sum_{i=1}^n\left( I(Y_i=1)[1-\phi(\alpha_1-x_i^T\beta)]
          - I(Y_i=2)\frac{\phi(\alpha_1-x_i^T\beta)[1-\phi(\alpha_1-x_i^T\beta)]}{\phi(\alpha_2-x_i^T\beta)-\phi(\alpha_1-x_i^T\beta)} \right)\\
        \\
     \end{aligned}
  }
\]

\[
  {\displaystyle
    \begin{aligned}
        \frac{\partial l(\alpha, \beta)}{\partial \alpha_2} &= \sum_{i=1}^n \left(
            I(Y_i=2)\frac{\frac{exp(x_i^T\beta-\alpha_2)}{[1+exp(x_i^T\beta-\alpha_2)]^2}}{\phi(\alpha_2-x_i^T\beta)-\phi(\alpha_1-x_i^T\beta)}
            -I(Y_i=3)\frac{\frac{exp(x_i^T\beta-\alpha_2)}{[1+exp(x_i^T\beta-\alpha_2)]^2}}{1-\phi(\alpha_2-x_i^T\beta)} \right)
            \\                       
            &=\sum_{i=1}^n\left( I(Y_i=2)\frac{\phi(\alpha_2-x_i^T\beta)[1-\phi(\alpha_2-x_i^T\beta)]}{\phi(\alpha_2-x_i^T\beta)-\phi(\alpha_1-x_i^T\beta)}
            - I(Y_i=3)\frac{\phi(\alpha_2-x_i^T\beta)[1-\phi(\alpha_2-x_i^T\beta)]}{1-\phi(\alpha_2-x_i^T\beta)} \right)      \qquad\qquad\qquad\qquad
  \end{aligned}
  }
\]   

### Proportional Odds Model with Penalty  
Although we only listed 13 predictors of interest, the Weather_Condition variable contains 53 levels alone, which can be problematic to fit especially if interactions are of interest. Meanwhile, aggregating the levels can be very subjective. To solve this problem, we integrate a <---insert the kind of penalty---> penalty term into the ordinary proportional odds model.

<---formulas for penalty and the likelihood function and gradient---->


### Variable Selection

  
## Random Forest
We implement the random forest method directly from the `caret` package in R for a comparison to the proportional odds model.  We use 5-fold Cross Validation on the training data to build the model. Additionally, a tuning grid is used to tune the parameter `mtry`, which defines the number of variables randomly collected to be sampled at each split time. The tuning grid used explored `mtry` values $1$, $2$, and $3$. 

### Ordinal Forest
It should be noted however, that the typical random forest classifier does not account for the fact that the classes are ordinal (i.e. class 1 is "closer" to class 2 than class 3). Therefore, it is of interest to explore a machine learning algorithm that can account for this. The R package `ordinalForest` does just that. We use the model with default hyperparameters on our data and compare to the traditional random forest and the proportional odds model.

### Downsampling
Since the levels of severity are not balanced, we also down-sampled the less severe outcomes to see if the predicted model improves in terms of accuracy and/or computation burden. We randomly sampled 1081 incidents from severity-1 incidents and 1081 incidents from severity-2 incidents, so that the three levels are balanced.

## Evaluation and Comparison of Models

In order to compare the performance of the different models built, we will use the attributes from the observations in our test set to predict their severity classification for each model. Then we can quantitatively compare which observations were correctly classified.

One way to do this is to measure the **accuracy** of the models on the test set. To do this, the fraction of the correctly classified observations is divided by the total number of observations in the test set. 

Another method to evaluate categorical models is to use **Cohen's Kappa**, which scales the accuracy to account for the predictions that are correct by guessing. We predict this will be more useful to us than the accuracy metric, since most of our data points come from Severity level 1 and accuracy could be very high simply by guessing all observations are in this class.

We can also compare the computational time it takes to build each model, called the **time to train**. This is important when working with large datasets. 

And finally, for a more visual comparison, we can look at the **Confusion Matrix** for the test set. This will be a 3 x 3 matrix in our case which tells us how many observations were predicted as class 1, 2, or 3 when their true classification is 1, 2, or 3.

# Results 

Note that not all of the code is run in this markdown document due to compiling time.

## Proportional Odds Model
```{r}


```
## Random Forest

RF Full Training Set

```{r, eval = FALSE}
#5-fold cross-validation
cv_5 = trainControl(method = "cv", number = 5)

#Tuning parameter
rf_grid = expand.grid(mtry = 1:3)

#Train model 
set.seed(3)
start = Sys.time()
rf_mod_red = train(
  Severity_c ~ Side + `Temperature(F)` + `Humidity(%)` + `Pressure(in)` + 
               `Visibility(mi)` + `Wind_Speed(mph)` + Crossing + Traffic_Signal +
               Sunrise_Sunset + weekday + interstate, 
  data = trn_data, 
  method = "rf",
  trControl = cv_5,
  tuneGrid = rf_grid
)
end = Sys.time()
print(end - start)

#Create plot of variable importance 
varImpPlot(rf_mod_red$finalModel)

#Obtain confusion matrix, accuracy, and kappa 
confusionMatrix(predict(rf_mod_red, newdata = tst_data), tst_data$Severity_c)
```

OF Full Training Data 

```{r, eval = FALSE}
#Prepare data
datatrain = trn_data%>% dplyr::select(Source, Side, `Temperature(F)`, `Humidity(%)`, `Pressure(in)`,
                                `Visibility(mi)`, `Wind_Speed(mph)`, Crossing, Traffic_Signal,
                                 Sunrise_Sunset, weekday, interstate, Severity_c)
datatest = tst_data %>% dplyr::select(Source, Side, `Temperature(F)`, `Humidity(%)`, `Pressure(in)`,
                                `Visibility(mi)`, `Wind_Speed(mph)`, Crossing, Traffic_Signal,
                                Sunrise_Sunset, weekday, interstate, Severity_c)

#Train Model 
set.seed(13847)
start = Sys.time()
ordforest <- ordfor(depvar = "Severity_c", data = datatrain)
sort(ordforest$varimp, decreasing = TRUE)
end = Sys.time()
print(end - start)

#Predict 
preds <- predict(ordforest, newdata = datatest)

#Obtain confusion matrix, accuracy, and kappa 
confusionMatrix(preds$ypred, datatest$Severity_c)
```

Downsampling Code 

```{r, eval = FALSE}
set.seed(12984)
downsample.trn <- trn_data[c(which(trn_data$Severity_c == 3),
                             sample(which(trn_data$Severity_c == 1), 1081), 
                             sample(which(trn_data$Severity_c == 2), 1081)),]
```

## Method Comparison 

The table below compares the 6 models built with all 12 predictors. We can see that the accuracy and Cohen's Kappa values are very comparable between the four models built with the entire Training Dataset. These metrics are slightly worse for the down sampled models. This is likely because of the immense loss of information when we apply a strict down sampling approach to our very imbalanced data. The most interesting result here is the difference in time to train between the models. 

```{r, echo = FALSE}
# create table from powerpoint 
table_df <- data.frame(Method = c("Proportional Odds", "OrdinalNet", "Random Forest", "Ordinal Forest", "RF Down Sample", "OF Down Sample"), 
                       Training_Set_Size = c(rep(75887,4), rep(3243, 2)), 
                       Accuracy = c(0.903, .903, .904, .904, 0.887, 0.886), 
                       Kappa = c(0.659, 0.664, 0.6696, 0.675, 0.661, 0.660), 
                       Time = c("1.7 minutes", "5.4  minutes", "11.5 minutes", "1.5 hours", "24 seconds", "7 minutes"))
knitr::kable(table_df, align = 'ccccc', caption = "Model Performance")
```

# Discussion 

comparison of POM and RF
  -accuracy
  -speed
  -applicability

## Limitations 

## Future Directions 

# Data Source 
The Car Accidents data set for North Carolina and the derived training and test data sets are provided in our project repository. Due to the size, we do not include the original nation-wide car accidents data set in our repository, but interested reader can find the dataset and related information on https://www.kaggle.com/sobhanmoosavi/us-accidents and https://smoosavi.org/datasets/us_accidents.  
  
  
# References 
[1] Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, and Rajiv
      Ramnath. “A Countrywide Traffic Accident Dataset.”, 2019.
  
[2] Moosavi, Sobhan, Mohammad Hossein Samavatian, Srinivasan Parthasarathy, Radu
      Teodorescu, and Rajiv Ramnath. "Accident Risk Prediction based on Heterogeneous
      Sparse Data: New Dataset and Insights." In proceedings of the 27th ACM SIGSPATIAL
      International Conference on Advances in Geographic Information Systems, ACM, 2019.
      
[3] Bing documentation on traffic incident data: https://docs.microsoft.com/en-us/bingmaps/rest-services/traffic/traffic-incident-data
   
[4] MapQuest documentation on traffic incident data: https://developer.mapquest.com/documentation/traffic-api/incidents/get/#response_field-severity
      
*** add sources for methods, particularly where we derived the proportional odds likelilhood/gradient from

